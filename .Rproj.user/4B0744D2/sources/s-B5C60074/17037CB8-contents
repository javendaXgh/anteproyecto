---
bibliography: references.bib
---

# Propuesta Técnica:

En este Capítulo se detalla la propuesta técnica de la Solución en la sección \@ref(propuestatec). Posteriormente se indica el Objetivo General \@ref(objetivogral) y los Objetivos Específicos \@ref(objetivosespe) que se aspiran cubrir en el desarrollo. A continuación se muestra el esquema general de la aplicación \@ref(esquemas), junto con el esquema de funcionamiento en los contenedores  \@ref(contenedores)  y se describe el funcionamiento de cada contenedor. 

Se realiza un análisis de factibilidad en la sección \@ref(factibilidad) para la implementación y se muestra un cronograma \@ref(cronograma) de actividades.

## Propuesta Técnica: {#propuestatec}

Crear una Solución que funcione como una aplicación web distribuida bajo la arquitectura cliente-servidor. Del lado del servidor se encontrarán contenedores que alojarán los distintos servicios necesarios para el funcionamiento.

Del lado del cliente se podrán formular los *querys* con múltiples atributos (la frase a buscar, la jerarquía académica, intervalo de fechas, facultad y/o escuela de adscripción).

La Solución permitirá generar procesos de extracción de información (*information retrieval*) y los resultados se mostrarán en tablas interactivas, gráficos y grafos de co-ocurrencias de palabras. Adicionalmente se indicarán recomendaciones de textos basados en la similitud que presente un documento con los otros.

Los textos del resumen de cada tesis con los cuales se conformará el *Corpus*, serán obtenidos y actualizados mediante técnicas de *web crawling* realizadas al repositorio Saber UCV.

Se opta por la estrategia de hacer el *web crawling* a los documentos contenidos en Saber UCV al no ser posible, al momento de realizar esta propuesta, la obtención de la base de datos de los documentos ahí alojados.

La Solución propuesta está diseñada para irse actualizando periódicamente incorporando los nuevos documentos que sean alojados en el repositorio Saber UCV.

Contará con un procedimiento que permite clasificar los documentos (tesis) por área académica, según donde haya efectuado estudios el autor del trabajo, al ser la tesis el requisito necesario para obtener el título de grado. Actualmente el repositorio Saber UCV no dispone de esta clasificación.

## Objetivo: {#objetivogral}

Crear una Solución que permita realizar la clasificación de documentos y la búsqueda de información sobre los trabajos de investigación que se encuentran en el Repositorio SABER UCV usando técnicas de extracción de información (*information retrieval*).

Para el procesamiento de las búsquedas será usado un sistema distribuido con distintos componentes (contenedores) que permitan la ingesta, procesamiento y transformación de los datos, al igual que el alojamiento de los mismos en una base de datos.

## Objetivos Específicos {#objetivosespe}

-   Querys multi atributo en distintas dimensiones: tiempo, jerarquías (pregrado, especializaciones, maestría y/o doctorado), facultad ,carreras o postgrados.

-   A cada resultado que arroje la búsqueda se le debe asignar un nivel de relevancia. El conjunto de los textos recuperados se debe mostrar ordenadamente de mayor a menor relevancia. La asignación de la relevancia será hecha mediante una función que cuente con distintos parámetros.

-   Los datos: textos, fechas, clasificaciones, y demás que sean necesarios para el funcionamiento de la Solución, deben registrarse en una base de datos estructurada y la ingesta y consulta se efectuará mediante un manejador de base de datos.

-   Generar recomendaciones de textos basados en la similitud coseno que presente un documento con cada uno de otros que conforman el *Corpus*.

-   En los documentos extraídos se debe contar con el enlace a los documentos que reposan en Saber UCV.

-   Permitir la concurrencia de accesos al Sistema.

-   La tolerancia a fallas en los contenedores.

-   Contar con el certificado SSL para acceso seguro por parte de los visitantes.

-   Procesar las coocurrencias de las palabras más comunes las cuales se deben visualizar mediante grafos.

-   En la representación de coocurrencias de palabras mediante grafos, se debe poder filtrar documentos interactivamente al hacer *click* con el *mouse* sobre los arcos que unen un par de nodos, donde cada uno de estos representa la co-ocurrencia de una dupla de palabras. El *click* generará el evento para el query sobre los documentos que contienen esa determinada co-ocurrencia.

## Esquema de la Aplicación WEB: {#esquemas}

Podemos representar el Sistema y sus interacciones mediante un esquema con un elevado grado de abstracción. Ver figura \@ref(fig:esquema).

```{r, esquema, echo=FALSE, out.width='100%',fig.cap='Esquema General'}
knitr::include_graphics(rep("formas/diagramageneral.png"))
```

En la figura \@ref(fig:esquema) se muestra como el SSCSU está diseñado para que mediante técnicas de *web crawling* se pueda extraer la información del repositorio Saber UCV. Posteriormente el sistema ante la consulta del usuario va a recuperar los documentos que sean relevantes, representando el conocimiento con la generación de jerarquías, rankings, coocurrencias de las palabras más mencionadas y recomendaciones de texto según similitudes.

El SSCSU se implementará mediante el uso de Docker. En la figura \@ref(fig:esquemadocker) se muestra el esquema que con los contenedores.

```{r, esquemadocker, echo=FALSE, out.width='90%',fig.cap='Diagrama Aplicación'}
knitr::include_graphics(rep("formas/diagrama_docker2.png"))
```

### Cliente - Servidor:

La arquitectura **cliente-servidor** en esta Propuesta se basa en:

#### 1 - Cliente - Navegador web:

El acceso del cliente, el navegador web, realiza la petición al enlace que direcciona al servidor que aloja la Solución. Actualmente se cuenta con un prototipo al que se puede acceder en la dirección <https://proyecta.me/>.

El sistema no está diseñado para usarse desde dispositivos móviles, aunque igualmente es viable el acceso.

#### 2 - Servidor:

El prototipo del sistema requiere para funcionar al menos estos recursos:

-   2 CPU virtual
-   2 GB de memoria RAM
-   50 GB de disco duro

En el servidor se instala el software Docker sobre el cual se despliegan los siguientes contenedores:

### Contenedores: {#contenedores}

#### Docker Compose:

Funciona como un orquestador para correr aplicaciones distribuidas en múltiples contenedores usando un archivo en formato yml donde se establecen las imágenes, los puertos y los volúmenes que serán usados y compartidos por cada uno de los contenedores.

#### Contenedor con Nginx:

Es el servidor web/proxy inverso de código abierto que sirve para redireccionar las peticiones del puerto 80 al puerto 8090. Mediante este contenedor también se define el certificado SSL para permitir conexiones por el protocolo HTTPS.

Este contenedor fue generado desde una imagen oficial de NGINX que se encuentra en el ***docker hub*** [^propuesta-1] sin añadir ninguna capa (lahyer) adicional.

[^propuesta-1]: repositorio de imágenes de contenedores de docker.

#### Contenedor con Cerbot:

Cerbot es una herramienta de código abierto que permite habilitar las conexiones mediante el protocolo HTTPS con el uso de un certificado "Let´s Encrypt". El uso de este certificado está asociado al uso de un dominio en el *deploy* de la aplicación.

Este contenedor fue generado desde una imagen de CERBOT del ***docker hub*** sin ninguna modificación posterior.

#### Contenedor con Shinyproxy: {#conshinyproxy}

Es una implementación del servidor "*Spring boo*t" que dará servicio a las aplicación web desarrolladas en *shiny* [^propuesta-2] \@ref(conshiny). Con el uso de este *middleware* se obtienen las siguientes ventajas:

[^propuesta-2]: Shiny un framework para crear aplicaciones web en el lenguaje de programación R.

- Ante cada petición de acceso al servidor se despliega un *workspace* completamente aislado, es decir, un contenedor distinto. Las aplicaciones desarrolladas en *shiny* son *single threaded* y adoptar esta estrategia representa una ventaja, motivado a que se pueden controlar los recursos de memoria y cpu asignados a cada contenedor que se despliega.

- Permite establecer *login* en el uso de la aplicación y grupos de usuarios. También da soporte a distintos métodos de autenticación. Si bien en estos momentos la aplicación es de libre acceso, en algún momento se pudiese restringir y no sería necesaria ninguna modificación en la arquitectura, más allá de cambiar el archivo de configuración.

- Uso de una tecnología estable y probada.

Es necesario destacar que originalmente *Shiny* como *framework* cuenta con su propio software que actúa como servidor, pero para tener acceso a ciertas funcionalidades es necesario pagar por el servicio directamente a la Fundación RStudio Software y usar el alojamiento que ellos proveen, no siendo todos los componentes de código abierto. Por ejemplo, el acceso mediante *login* no está disponible en la versión libre del *Shiny Server* sino en la *Shiny Server Professional*.

Ciertas configuraciones de librerías e incluso la propia contenerización de la aplicación, no es posible usando el servicio pago, así que la propuesta acá adoptada, si bien representa un mayor esfuerzo en la configuración, claramente implica que se obtienen una serie de ventajas, por todas las adaptaciones y control que es posible realizar al y sobre el sistema.

Este contenedor funciona en el puerto 2375 y fue generado desde la imagen del docker hub *Shinyproxy* sin ninguna modificación.

#### Contenedor con "*R Shiny Web App framework*": {#conshiny}

En este contenedor es donde reposa la aplicación web con todas las librerías necesarias para generar las visualizaciones y remitir los *querys* al contenedor del manejador de la base de datos \@ref(conposgres) . Como comentamos anteriormente, cada vez que ocurre desde el navegador del cliente una petición de acceso, desde el contenedor *shinyproxy* \@ref(conshinyproxy), se crea una replica de este contenedor con todos los elementos necesarios para que la app funcione correctamente.

En caso de presentar alguna falla, el sistema sería tolerante, porque se pueden seguir recibiendo peticiones que replicarían una imagen nueva del contenedor sin afectar al que presentase el fallo, o viceversa.

Desde este contenedor se realiza el acceso de lectura al contenedor que contiene PostgreSQL \@ref(conposgres) donde reposa la base de datos que contiene los textos ya procesados.

Por los momentos no hay escritura de datos en las tablas, pero está contemplado que se registren los querys formulados en alguna tabla, junto con los documentos que el usuario revisa mediante las interacciones, para así generar métricas de calidad del sistema y del uso que se le da.

La imagen que se usa en este servidor fue definida a medida con todos los recursos necesarios.

En un posterior Capítulo donde se mostrará el proceso de desarrollo de la Solución, serán descritas todas las librerías que se encuentran incluidas en este contenedor.

Varios de los procesos que se ejecutan en este contenedor ocurren al momento de recibir un *query,* no obstante todos los procesos que puedan ser pre computados, se trata de ejecutarlos previamente en el contenedor "R Servicios" \@ref(conservicios), para lograr así la disminución de los tiempos.

Funcionalidades principales: **ENTRADAS**

- Contiene un campo para la entrada de texto que generará el query.

- Contiene un selector para indicar si se quiere generar la coocurrencia de palabras

- Contiene tablas para seleccionar:

    1)  Nivel académico del trabajo. Opciones (pregrado, especialización, maestría, doctorado).
    2)  Facultad o Centro de adscripción. Opciones: 11 Facultades más un centro (CENDES).
    3)  Nombre del pregrado o postgrado. En total son 412 las opciones.

    Cada una de las tablas anteriores se actualiza según se vayan seleccionando las relaciones y la disponibilidades. Por ejemplo, al seleccionar pregrado solo se mostrarán los nombres de las carreras de pregrado, pero si se selecciona también el nombre de la Facultad, sólo se mostrarán las carreras de pregrado dentro de la Facultad seleccionada. Para una determinada tabla también se permiten selecciones múltiples dando una total flexibilidad al momento de ejecutar los *querys*.

**SALIDAS** - Ante el *query* se genera:

- Una tabla creada con la librería *reactable*. En la misma se muestra cada uno de los documentos recuperados con los distintos atributos disponibles: autor, fecha, palabras claves, texto resumen. El orden en que aparece está generado con una función de ranking. Adicionalmente se muestra un enlace al repositorio Saber UCV que es donde se encuentra alojado el respectivo trabajo (el documento en PDF). Igualmente se presentan los textos que tienen mayor similitud con el texto seleccionado.

- Un gráfico con la frecuencia por año de los trabajos extraídos mediante el *query*. El gráfico se generá con la librería *apexcharter* que es un wraper para Javascript, por lo cual el gráfico tiene ciertas interactividades. Con el *hoover* muestra el valor de cada columna.

- Gráfico de coocurrencia interactivo de palabras: se genera mediante la librería de *VisNetwork* que también es un *wrapper* de javascript. Este gráfico permite seleccionar un arco de unión entre dos palabras coocurrentes. Al realizar la selección se filtran un subconjunto de los documentos que contienen ambas palabras representadas por nodos. Los documentos filtrados se mostrarán en una tabla contigua, también generada en *reactable*, donde sólo se incluye el texto resumen de cada trabajo. En un próximo Capítulo a desarrollar será mencionado el diseño y funcionamiento a detalle de esta visualización.

- Gráfico de coocurrencia estático de palabras: mediante la librería *ggraph* son generados un par de gráficos. El primero con la misma coocurrencia de palabras vista anteriormente pero esta vez generada en una visualización estática. El segundo gráfico también muestra la coocurrencia, pero solo de palabras que ocurren una seguida de otra dentro del texto resumen.

Con la librería *UdPipe* se generan las estructuras de datos necesarias para generar los grafos (arcos y nodos).



#### Contenedor con PostgreSQL: {#conposgres}

En este contenedor tenemos una imagen de PostgreSQL versión 13.3. No fue realizada ninguna otra modificación distinta a la definición de usuarios y poblado desde base de datos incluyendo un volumen compartido para garantizar que tengamos "datos persistentes. Este contenedor recibe consultas del contenedor "R Shiny Web App framework" \@ref(conshiny) y escritura desde el contenedor "R imagen Servicios" \@ref(conservicios).

En este contenedor ocurre la indexación de la base de datos y la generación del ranking al procesar el resultado con la función tsrank [^propuesta-3]. Se cuenta con dos tablas no relacionales. 
[^propuesta-3]: esta función mide la relevancia de los documentos para una consulta en particular, de modo que cuando haya muchas coincidencias, las más relevantes puedan mostrarse primero tomando en cuenta la información léxica, de proximidad y estructural del documento (título, cuerpo del documento, etc).

En una tabla se encuentra la identificación del documento, la fecha de creación y propiamente los textos que mediante el Tsvector [^propuesta-4] almacena el título, el resumen, el autor y las palabras claves.

[^propuesta-4]: El Tsvector es una función de postgresql que crea una estructura de datos que es una lista ordenada de distintos lexemas, que son palabras que se han normalizado para fusionar diferentes variantes de la misma palabra mediante el algoritmo de Porter.

La otra tabla contiene otro procesamiento que se le hace a los textos, clasificando cada una de las palabras mediante el *part of speach* , el documento al que está asociada y el lemma.

El TSvector es la estructura de datos que permite la búsqeda de texto completa (*Full Text Seach*) mediante la función de *postgresql* denominada *tsquery*. En un futuro capítulo a desarrollar será mostrado el diseño de las tablas con sus campos.


#### Contenedor con "R Imagen Servicios": {#conservicios}

En este contenedor se creó una imagen con todos los servicios necesarios para realizar el web crawling, procesamientos de textos y archivos descargados desde Saber.UCV, poblado y llamar a las funciones para la escritura en la base de datos, programación de rutinas de actualización (cron) y demás servicios que se debe ejecutar periódicamente. La imagen usada es la del proyecto ***Rocker*** [@RJ-2017-065:2017] ,la cual es una versión ampliamente probada y optimizada en, y por, la comunidad de usuarios de R.

Posteriormente serán descritas todas las librerías que fueron añadidas mediante una capa (lahyer) a este contenedor. Por los momentos podemos citar que se encuentran agregadas las siguientes:

##### Text Mining y NLP:

Generalmente las distintas librerías que permiten realizar procesos de *Natural Language Processing* también hacen procesos de *Text Mining* parcial o totalmente. En la investigación fueron evaluadas múltiples librerías como *Spacy, Quanteda, OPENLP, CoreNLP, Freeling y Udpipe*.

En una futura entrega se hará una breve mención a cada una y la razón por la cual se adoptó Spacy para varios de los procesos de NLP.

Para ejecutar *Spacy* es necesario usar los archivos que se encuentran en el contenedor *"Python Spacy"* , \@ref(conspacy) donde está instalada la libraría *Spacy* que corre en *Python*.

Procesos que se ejecutan llamando al contenedor "Python Spacy": Tokenización, POS y Lematización.


También en este contenedor se realizan los siguientes procesos:

1.  Poblado base de datos: se hace el *web crawling* para el poblado inicial y adicionales de la base de dato, con los textos de los Resúmenes.

2.  Clasificación de los documentos: mediante una rutina compuesta por varios algoritmos serán clasificados los distintos trabajos según lo antes expuesto.

3.  Cálculo de la Similitud de los documentos: cuando se ha realizado la lematización de las palabras se procede a generar una matriz de tipo Td-Idf (term document- inverse document frecuency), que sirve de insumo para el cálculo de similitud entre los documentos. Este cálculo de similitud se realiza con la librería Quanteda.texstats y se usa la medida de similitud coseno, ya que varios autores la sitúan como una de las mejores formas de comparar la similitud entre un documento y otro.

#### Contenedor con "Python Spacy": {#conspacy}

Se creó una imagen que contiene un ubuntu con python, spacy y el modelo de Spacy [es_core_news_sm](https://spacy.io/models/es#es_core_news_sm) . Su función es que mediante un volumen compartido pueda ser invocado desde el contenedor "R Imagen Servicios" \@ref(conservicios) para así realizar los procesamientos de NLP antes descritos.

## Factibilidad: {#factibilidad}

Para la propuesta del SCSU se hizo una evaluación de la factibilidad del desarrollo del proyecto que consistió en hacer pruebas de ***web crawling*** sobre el repositorio Saber UCV al no ser viable la obtención del conjunto de datos por otro medio. Igualmente se realizaron pruebas sobre el hardware disponible con arquitecturas similares a la que se propondrá más adelante en nuestro desarrollo.

Estas pruebas fueron exitosas por lo cual no se estima que exista algún factor que impida la implementación del Sistema acá expuesto.

## Cronograma: {#cronograma}

El cronograma de desarrollo propuesto es el siguiente:



```{r cronograma, echo=FALSE, warning=FALSE, out.width='80%'}

p <- data.frame(
  
  stringsAsFactors = FALSE,
                ID = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, NA),
             Tarea = c("web craling inicial",
                       "diseño algoritmo clasificación",
                       "diseño componentes de la aplicación","Implementación de componentes",
                       "Pruebas contenedores Docker","Pruebas de software",
                       "implementación en servidor","Elaboración de trabajo especial de grado",'TOTAL'),
          cantidad = c(2L, 3L, 4L, 4L, 1L, 1L, 1L, 8L, 24L),
            medida = c("semanas","semanas","semanas",
                       "semanas","semanas","semanas","semanas","semanas",
                       "semanas"),
       predecesora = c(0, 1L, 1L, 3L, 4L, 5L, 6L, 7L, NA)
)

flextable::flextable(p)%>%
  flextable::set_caption('Cronograma de desarrollo de la Solución')%>%
  flextable::autofit()%>%
  flextable::bold(9)
```